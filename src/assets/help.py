import cfscrape
import requests
from bs4 import BeautifulSoup

cities = ['Hargeisa', 
'King Edward Point', 
'Port-aux-FranÃ§ais', 
'Jerusalem', 
'Mariehamn', 
'Yaren', 
'Marigot', 
'Atafu', 
'El-AaiÃºn', 
'Kabul', 
'Tirana', 
'Algiers', 
'Pago Pago', 
'Andorra la Vella', 
'Luanda', 
'The Valley', 
"Saint John's", 
'Buenos Aires', 
'Yerevan', 
'Oranjestad', 
'Canberra', 
'Vienna', 
'Baku', 
'Nassau', 
'Manama', 
'Dhaka', 
'Bridgetown', 
'Minsk', 
'Brussels', 
'Belmopan', 
'Porto-Novo', 
'Hamilton', 
'Thimphu', 
'La Paz', 
'Sarajevo', 
'Gaborone', 
'Brasilia', 
'Road Town', 
'Bandar Seri Begawan', 
'Sofia', 
'Ouagadougou', 
'Rangoon', 
'Bujumbura', 
'Phnom Penh', 
'Yaounde', 
'Ottawa', 
'Praia', 
'George Town', 
'Bangui', 
"N'Djamena", 
'Santiago', 
'Beijing', 
'The Settlement', 
'West Island', 
'Bogota', 
'Moroni', 
'Kinshasa', 
'Brazzaville', 
'Avarua', 
'San Jose', 
'Yamoussoukro', 
'Zagreb', 
'Havana', 
'Willemstad', 
'Nicosia', 
'Prague', 
'Copenhagen', 
'Djibouti', 
'Roseau', 
'Santo Domingo', 
'Quito', 
'Cairo', 
'San Salvador', 
'Malabo', 
'Asmara', 
'Tallinn', 
'Addis Ababa', 
'Stanley', 
'Torshavn', 
'Suva', 
'Helsinki', 
'Paris', 
'Papeete', 
'Libreville', 
'Banjul', 
'Tbilisi', 
'Berlin', 
'Accra', 
'Gibraltar', 
'Athens', 
'Nuuk', 
"Saint George's", 
'Hagatna', 
'Guatemala City', 
'Saint Peter Port', 
'Conakry', 
'Bissau', 
'Georgetown', 
'Port-au-Prince', 
'Vatican City', 
'Tegucigalpa', 
'Budapest', 
'Reykjavik', 
'New Delhi', 
'Jakarta', 
'Tehran', 
'Baghdad', 
'Dublin', 
'Douglas', 
'Jerusalem', 
'Rome', 
'Kingston', 
'Tokyo', 
'Saint Helier', 
'Amman', 
'Astana', 
'Nairobi', 
'Tarawa', 
'Pyongyang', 
'Seoul', 
'Pristina', 
'Kuwait City', 
'Bishkek', 
'Vientiane', 
'Riga', 
'Beirut', 
'Maseru', 
'Monrovia', 
'Tripoli', 
'Vaduz', 
'Vilnius', 
'Luxembourg', 
'Skopje', 
'Antananarivo', 
'Lilongwe', 
'Kuala Lumpur', 
'Male', 
'Bamako', 
'Valletta', 
'Majuro', 
'Nouakchott', 
'Port Louis', 
'Mexico City', 
'Palikir', 
'Chisinau', 
'Monaco', 
'Ulaanbaatar', 
'Podgorica', 
'Plymouth', 
'Rabat', 
'Maputo', 
'Windhoek', 
'Kathmandu', 
'Amsterdam', 
'Noumea', 
'Wellington', 
'Managua', 
'Niamey', 
'Abuja', 
'Alofi', 
'Kingston', 
'Saipan', 
'Oslo', 
'Muscat', 
'Islamabad', 
'Melekeok', 
'Panama City', 
'Port Moresby', 
'Asuncion', 
'Lima', 
'Manila', 
'Adamstown', 
'Warsaw', 
'Lisbon', 
'San Juan', 
'Doha', 
'Bucharest', 
'Moscow', 
'Kigali', 
'Gustavia', 
'Jamestown', 
'Basseterre', 
'Castries', 
'Saint-Pierre', 
'Kingstown', 
'Apia', 
'San Marino', 
'Sao Tome', 
'Riyadh', 
'Dakar', 
'Belgrade', 
'Victoria', 
'Freetown', 
'Singapore', 
'Philipsburg', 
'Bratislava', 
'Ljubljana', 
'Honiara', 
'Mogadishu', 
'Pretoria', 
'Juba', 
'Madrid', 
'Colombo', 
'Khartoum', 
'Paramaribo', 
'Longyearbyen', 
'Mbabane', 
'Stockholm', 
'Bern', 
'Damascus', 
'Taipei', 
'Dushanbe', 
'Dar es Salaam', 
'Bangkok', 
'Dili', 
'Lome', 
"Nuku'alofa", 
'Port of Spain', 
'Tunis', 
'Ankara', 
'Ashgabat', 
'Grand Turk', 
'Funafuti', 
'Kampala', 
'Kyiv', 
'Abu Dhabi', 
'London', 
'Washington, D.C.', 
'Montevideo', 
'Tashkent', 
'Port-Vila', 
'Caracas', 
'Hanoi', 
'Charlotte Amalie', 
'Mata-Utu', 
'Sanaa', 
'Lusaka', 
'Harare', 
'Washington', 
'North Nicosia', 
'Diego Garcia']

scraper = cfscrape.create_scraper()

for city in cities: 

    #for each city, search for it on pixabay
    search_query = city.replace(" ", "+")
    url = f"https://pixabay.com/images/search/{search_query} /"

    response = scraper.get(url)
    soup = BeautifulSoup(response.text, "html.parser")

    # Find the container of
    # the specfifc image on the screen
    container = soup.find('div', class_='container--MwyXl')
    if container:

        # Find the image
        img_container = soup.find('a', class_="link--WHWzm")

        img_url = img_container["href"]
        response = scraper.get(img_url) 
        soup = BeautifulSoup(response.text, "html.parser")

        # Find the container of
        # the specfifc image on the screen
        container = soup.find('div', class_='container--3Mtk4')
        img_container = container.find("img")
        img_url = img_container["src"]
        response = requests.get(img_url)
        with open(f"{city}.jpg", "wb") as file:
            file.write(response.content)
        print(f"Downloaded image for {city}")










        # Iterate over the nested divs to find the first img element
        # for div in nested_divs:
        #     if div.find('img'):
        #         img = div.find('img')
        #         image_url = img['src']
        #         response = requests.get(image_url)
        #         with open(f"{city}.jpg", "wb") as file:
        #             file.write(response.content)
        #         print(f"Downloaded image for {city}")
        #         break  # Exit the loop after finding the first image
